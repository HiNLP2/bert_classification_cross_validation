{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理模块\n",
    "### 思路：\n",
    "1. 分层抽样+多个小模型vote投票，是一种模型集成技术，可以提升指标的准确率，一般用于一些刷榜单时候，缺点是耗费更大的算力\n",
    "2. 分层抽样，目前用的5折，也就是其中4份用于train，另外1份用于test，训练5个模型（也可以使用不同的模型，但是分层抽样更有用）\n",
    "3. 每个模型只使用了抽样的部分数据，因此多个模型的结果应该不一致，这些样本人工再过一遍，然后用校对后的样本进行训练\n",
    "4. 对于每日的批数据，可以用kfold模型进行达标，对不一致的标签进行人工核对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch4keras.snippets import YamlConfig\n",
    "import os\n",
    "\n",
    "config = YamlConfig('./config.yaml')\n",
    "data_dir = config['data_dir']\n",
    "data_path = os.path.join(data_dir, 'cls.xlsx')\n",
    "map_path = os.path.join(data_dir, 'category_map.xlsx')\n",
    "data = pd.read_excel(data_path)\n",
    "map_data =  pd.read_excel(map_path)\n",
    "\n",
    "if 'class_id' in data.columns:\n",
    "    data.drop('class_id', axis=1, inplace=True)\n",
    "\n",
    "data = pd.merge(data, map_data[['class_id', 'class_name']], on='class_name')\n",
    "print('数据量:', len(data))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单数据统计\n",
    "data['class_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分层抽样并保存\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import json\n",
    "\n",
    "X, y = data[['content', 'class_id']], data['class_name']\n",
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    train_data = []\n",
    "    content, class_id = X.iloc[train_index]['content'], X.iloc[train_index]['class_id']\n",
    "    for c, id, l in zip(content, class_id, y[train_index]):\n",
    "        train_data.append(json.dumps({'content': c, 'class_id': id, 'class_name': l}, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    test_data = []\n",
    "    content, class_id = X.iloc[test_index]['content'], X.iloc[test_index]['class_id']\n",
    "    for c, id, l in zip(content, class_id, y[train_index]):\n",
    "        test_data.append(json.dumps({'content': c, 'class_id': id, 'class_name': l}, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    with open(f'./data/fold_{i}_train.jsonl', 'w', encoding='utf-8') as f:\n",
    "        f.writelines(train_data)\n",
    "    \n",
    "    with open(f'./data/fold_{i}_test.jsonl', 'w', encoding='utf-8') as f:\n",
    "        f.writelines(test_data)\n",
    "    print('标签数: ', len(set(class_id)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
